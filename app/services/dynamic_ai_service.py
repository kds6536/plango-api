"""
ë™ì  AI ì„œë¹„ìŠ¤
ê´€ë¦¬ì ì„¤ì •ì— ë”°ë¼ OpenAI ë˜ëŠ” Google Geminië¥¼ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©
"""

import os
import json
from typing import Optional, Dict, Any, List
import openai
import google.generativeai as genai

from app.config import settings
from app.utils.logger import get_logger
from app.routers.admin import load_ai_settings_from_db
from app.services.supabase_service import supabase_service

logger = get_logger(__name__)

class DynamicAIService:
    """ê´€ë¦¬ì ì„¤ì •ì— ë”°ë¼ ë™ì ìœ¼ë¡œ AI ì œê³µìë¥¼ ì„ íƒí•˜ëŠ” ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.openai_client = None
        self.gemini_model = None
        self._setup_clients()
    
    def _setup_clients(self):
        """AI í´ë¼ì´ì–¸íŠ¸ë“¤ì„ ì´ˆê¸°í™”"""
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
            if settings.OPENAI_API_KEY:
                self.openai_client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)
                logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            # Gemini í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
            if settings.GEMINI_API_KEY:
                genai.configure(api_key=settings.GEMINI_API_KEY)
                self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')
                logger.info("Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _get_current_provider(self) -> str:
        """í˜„ì¬ ì„¤ì •ëœ AI ì œê³µìë¥¼ Supabase DBì—ì„œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            settings_dict = load_ai_settings_from_db()
            return settings_dict.get("default_provider", "gemini")
        except Exception as e:
            logger.error(f"AI provider DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return "gemini"
    
    def _create_default_settings_file(self, settings_file: str):
        """ê¸°ë³¸ AI ì„¤ì • íŒŒì¼ ìƒì„±"""
        try:
            # data ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(os.path.dirname(settings_file), exist_ok=True)
            
            default_settings = {
                # ê¸°ë³¸ ì œê³µìë¥¼ 'gemini'ë¡œ ë³€ê²½
                "provider": "gemini",
                "last_updated": "2025-01-02T00:00:00Z",
                "settings": {
                    "openai": {
                        "model": "gpt-3.5-turbo",
                        "temperature": 0.7,
                        "max_tokens": 2000
                    },
                    "gemini": {
                        "model": "gemini-1.5-flash",
                        "temperature": 0.7,
                        "max_tokens": 2000
                    }
                }
            }
            
            with open(settings_file, 'w', encoding='utf-8') as f:
                json.dump(default_settings, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ê¸°ë³¸ AI ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ: {settings_file}")
            
        except Exception as e:
            logger.error(f"ê¸°ë³¸ AI ì„¤ì • íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
    
    async def generate_text(self, prompt: str, max_tokens: int = 2000) -> str:
        """
        í˜„ì¬ ì„¤ì •ëœ AI ì œê³µìë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±
        """
        # providerë¥¼ generate_text í˜¸ì¶œ ì‹œë§ˆë‹¤ ì‹¤ì‹œê°„ìœ¼ë¡œ ì½ìŒ
        current_provider = self._get_current_provider()
        
        # === Railway ë¡œê·¸: AI í˜¸ì¶œ ì‹œì‘ ===
        logger.info(f"ğŸ¤– [AI_START] AI í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘")
        logger.info(f"ğŸ”§ [AI_PROVIDER] í˜„ì¬ AI ì œê³µì: {current_provider}")
        logger.info(f"ğŸ“ [PROMPT_LENGTH] í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ê¸€ì")
        logger.info(f"ğŸ›ï¸ [MAX_TOKENS] ìµœëŒ€ í† í°: {max_tokens}")
        logger.info(f"ğŸ“ [PROMPT_PREVIEW] í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {prompt[:200]}...")
        
        try:
            if current_provider == "gemini":
                logger.info(f"ğŸŸ¢ [AI_GEMINI] Google Geminië¡œ í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘")
                result = await self._generate_with_gemini(prompt, max_tokens)
            else:
                logger.info(f"ğŸ”µ [AI_OPENAI] OpenAIë¡œ í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘")
                result = await self._generate_with_openai(prompt, max_tokens)
            
            # === Railway ë¡œê·¸: AI í˜¸ì¶œ ì„±ê³µ ===
            logger.info(f"âœ… [AI_SUCCESS] AI í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ")
            logger.info(f"ğŸ“Š [RESULT_LENGTH] ì‘ë‹µ ê¸¸ì´: {len(result)} ê¸€ì")
            logger.info(f"ğŸ“„ [RESULT_PREVIEW] ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {result[:200]}...")
            
            return result
            
        except Exception as e:
            # === Railway ë¡œê·¸: AI í˜¸ì¶œ ì‹¤íŒ¨ ===
            logger.error(f"âŒ [AI_ERROR] {current_provider} AI ìƒì„± ì‹¤íŒ¨")
            logger.error(f"ğŸš¨ [ERROR_TYPE] {type(e).__name__}")
            logger.error(f"ğŸ“ [ERROR_MESSAGE] {str(e)}")
            # ë‹¤ë¥¸ AIë¡œ ì¬ì‹œë„í•˜ì§€ ì•Šê³ , ì˜ˆì™¸ë¥¼ ê·¸ëŒ€ë¡œ ì˜¬ë ¤ fallback ì²˜ë¦¬
            raise
    
    async def _generate_with_openai(self, prompt: str, max_tokens: int) -> str:
        """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±"""
        if not self.openai_client:
            raise Exception("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì—¬í–‰ ì¼ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ìµœì ì˜ ì—¬í–‰ ì¼ì •ì„ ìƒì„±í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7
            )
            
            result = response.choices[0].message.content.strip()
            logger.info(f"OpenAI ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(result)} ê¸€ì)")
            return result
            
        except Exception as e:
            logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise Exception(f"OpenAI í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    async def _generate_with_gemini(self, prompt: str, max_tokens: int) -> str:
        """Google Geminië¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±"""
        if not self.gemini_model:
            raise Exception("Gemini ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            # Geminiìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            full_prompt = f"""ë‹¹ì‹ ì€ ì—¬í–‰ ì¼ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ìµœì ì˜ ì—¬í–‰ ì¼ì •ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ìš”ì²­:
{prompt}

ì‘ë‹µì€ ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ ì—¬í–‰ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."""

            response = self.gemini_model.generate_content(
                full_prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=max_tokens,
                    temperature=0.7,
                )
            )
            
            result = response.text.strip()
            logger.info(f"Gemini ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(result)} ê¸€ì)")
            return result
            
        except Exception as e:
            logger.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise Exception(f"Gemini í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    async def create_search_queries(self, city: str, country: str, existing_places: List[str] = None) -> Dict[str, str]:
        """
        AIê°€ ì¤‘ë³µì„ í”¼í•˜ëŠ” ìµœì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ 4ê°œ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìƒì„±
        
        Args:
            city: ë„ì‹œëª…
            country: êµ­ê°€ëª…  
            existing_places: ê¸°ì¡´ì— ì¶”ì²œëœ ì¥ì†Œ ëª©ë¡ (ì¤‘ë³µ ë°©ì§€ìš©)
            
        Returns:
            Dict[str, str]: ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ ì¿¼ë¦¬
            {
                "tourism": "ì„œìš¸ ê²½ë³µê¶ ì°½ë•ê¶ ë¶ˆêµ ì‚¬ì°°",
                "food": "ì„œìš¸ í•œì‹ ë§›ì§‘ ê°ˆë¹„ ëƒ‰ë©´",  
                "activity": "ì„œìš¸ í•œê°• ê³µì› íŠ¸ë ˆí‚¹",
                "accommodation": "ì„œìš¸ í˜¸í…” ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤"
            }
        """
        logger.info(f"ğŸ” [AI_SEARCH_PLAN] AI ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½ ì‹œì‘ - {city}, {country}")
        
        try:
            # Supabaseì—ì„œ ê²€ìƒ‰ ê³„íš ì „ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¡°íšŒ (ê³ ì •: search_strategy_v1)
            prompt_template = await supabase_service.get_master_prompt("search_strategy_v1")
            
            # ê¸°ì¡´ ì¥ì†Œ ëª©ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            existing_places_text = ""
            if existing_places:
                existing_places_text = f"""
ì´ë¯¸ ì¶”ì²œëœ ì¥ì†Œë“¤ (ì¤‘ë³µ ê¸ˆì§€):
{', '.join(existing_places)}

ìœ„ ì¥ì†Œë“¤ê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ì™„ì „íˆ ìƒˆë¡œìš´ ì¥ì†Œë§Œ ê²€ìƒ‰í•´ì£¼ì„¸ìš”."""
            else:
                existing_places_text = "ì²« ë²ˆì§¸ ê²€ìƒ‰ì´ë¯€ë¡œ ì œì•½ ì—†ì´ ìµœê³ ì˜ ì¥ì†Œë“¤ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”."
            
            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ë°ì´í„° ì¹˜í™˜
            from string import Template
            template = Template(prompt_template)
            
            search_prompt = template.safe_substitute(
                city=city,
                country=country,
                existing_places=existing_places_text
            )
            
            logger.info(f"ğŸ“‹ [SEARCH_PROMPT] ê²€ìƒ‰ ê³„íš í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({len(search_prompt)} ê¸€ì)")
            
            # AIì—ê²Œ ê²€ìƒ‰ ê³„íš ìš”ì²­
            response = await self.generate_text(search_prompt, max_tokens=1000)
            
            # JSON ì‘ë‹µ íŒŒì‹±
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                search_queries = json.loads(json_match.group())
                logger.info(f"âœ… [SEARCH_QUERIES] AI ê²€ìƒ‰ ê³„íš ìƒì„± ì™„ë£Œ: {search_queries}")
                return search_queries
            else:
                raise ValueError("AI ì‘ë‹µì—ì„œ JSON í˜•íƒœì˜ ê²€ìƒ‰ ê³„íšì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"âŒ [SEARCH_PLAN_ERROR] AI ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: {e}")
            # ë” ì´ìƒ í´ë°±ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì¦‰ì‹œ ì‹¤íŒ¨ ì²˜ë¦¬
            raise

    def _get_fallback_search_strategy_prompt(self) -> str:
        """Supabase í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ë‚´ì¥ í´ë°± í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ì—¬í–‰ ì¥ì†Œ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë„ì‹œì—ì„œ ì¤‘ë³µ ì—†ëŠ” ìµœì ì˜ ì¥ì†Œ ê²€ìƒ‰ ì „ëµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.

**ë„ì‹œ ì •ë³´:**
- ë„ì‹œ: $city
- êµ­ê°€: $country

**ì¤‘ë³µ ë°©ì§€ ì¡°ê±´:**
$existing_places

**ì„ë¬´:**
ì•„ë˜ 4ê°œ ì¹´í…Œê³ ë¦¬ë³„ë¡œ Google Places API Text Searchì— ì‚¬ìš©í•  ìµœì ì˜ ê²€ìƒ‰ì–´(textQuery)ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ê²€ìƒ‰ ì „ëµ ì›ì¹™:**
1. ê° ì¹´í…Œê³ ë¦¬ë§ˆë‹¤ ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´ ì‚¬ìš©
2. ê¸°ì¡´ ì¶”ì²œ ì¥ì†Œì™€ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ë‹¤ë¥¸ í‚¤ì›Œë“œ ì„ íƒ  
3. í˜„ì§€ ë¬¸í™”ì™€ íŠ¹ìƒ‰ì„ ë°˜ì˜í•œ ê²€ìƒ‰ì–´ ìš°ì„ 
4. ë„ˆë¬´ ì¼ë°˜ì ì´ì§€ ì•Šê³ , ë„ˆë¬´ êµ¬ì²´ì ì´ì§€ë„ ì•Šì€ ì ì ˆí•œ ìˆ˜ì¤€

**ì¹´í…Œê³ ë¦¬ë³„ ìš”êµ¬ì‚¬í•­:**
- tourism: ê´€ê´‘ì§€, ëœë“œë§ˆí¬, ë°•ë¬¼ê´€, ë¬¸í™”ìœ ì  ë“±
- food: ìŒì‹ì , ì¹´í˜, í˜„ì§€ ìŒì‹, ë§›ì§‘ ë“±
- activity: ì•¡í‹°ë¹„í‹°, ì—”í„°í…Œì¸ë¨¼íŠ¸, ìŠ¤í¬ì¸ , ì•¼ì™¸í™œë™ ë“±  
- accommodation: í˜¸í…”, ìˆ™ë°•, ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤, ë¦¬ì¡°íŠ¸ ë“±

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "tourism": "êµ¬ì²´ì ì¸ ê´€ê´‘ ê²€ìƒ‰ì–´",
  "food": "êµ¬ì²´ì ì¸ ìŒì‹ ê²€ìƒ‰ì–´", 
  "activity": "êµ¬ì²´ì ì¸ ì•¡í‹°ë¹„í‹° ê²€ìƒ‰ì–´",
  "accommodation": "êµ¬ì²´ì ì¸ ìˆ™ë°• ê²€ìƒ‰ì–´"
}}

ì˜ˆì‹œ:
{{
  "tourism": "Seoul Gyeongbokgung Palace Bukchon Hanok Village",
  "food": "Seoul Korean BBQ galbi naengmyeon restaurants",
  "activity": "Seoul Han River park cycling hiking",
  "accommodation": "Seoul boutique hotels guesthouses Myeongdong"
}}"""

    def get_provider_info(self) -> Dict[str, Any]:
        """í˜„ì¬ AI ì œê³µì ì •ë³´ ë°˜í™˜"""
        current_provider = self._get_current_provider()
        
        provider_info = {
            "current_provider": current_provider,
            "available_providers": [],
            "provider_status": {}
        }
        
        # OpenAI ìƒíƒœ í™•ì¸
        if self.openai_client and settings.OPENAI_API_KEY:
            provider_info["available_providers"].append("openai")
            provider_info["provider_status"]["openai"] = "available"
        else:
            provider_info["provider_status"]["openai"] = "not_configured"
        
        # Gemini ìƒíƒœ í™•ì¸
        if self.gemini_model and settings.GEMINI_API_KEY:
            provider_info["available_providers"].append("gemini")
            provider_info["provider_status"]["gemini"] = "available"
        else:
            provider_info["provider_status"]["gemini"] = "not_configured"
        
        return provider_info

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
dynamic_ai_service = DynamicAIService() 