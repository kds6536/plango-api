"""
ë™ì  AI ì„œë¹„ìŠ¤
ê´€ë¦¬ì ì„¤ì •ì— ë”°ë¼ OpenAI ë˜ëŠ” Google Geminië¥¼ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©
"""

import os
import json
from typing import Optional, Dict, Any
import openai
import google.generativeai as genai

from app.config import settings
from app.utils.logger import get_logger

logger = get_logger(__name__)

class DynamicAIService:
    """ê´€ë¦¬ì ì„¤ì •ì— ë”°ë¼ ë™ì ìœ¼ë¡œ AI ì œê³µìë¥¼ ì„ íƒí•˜ëŠ” ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.openai_client = None
        self.gemini_model = None
        self._setup_clients()
    
    def _setup_clients(self):
        """AI í´ë¼ì´ì–¸íŠ¸ë“¤ì„ ì´ˆê¸°í™”"""
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
            if settings.OPENAI_API_KEY:
                self.openai_client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)
                logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            # Gemini í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
            if settings.GEMINI_API_KEY:
                genai.configure(api_key=settings.GEMINI_API_KEY)
                self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')
                logger.info("Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _get_current_provider(self) -> str:
        """í˜„ì¬ ì„¤ì •ëœ AI ì œê³µìë¥¼ ê°€ì ¸ì˜¤ê¸°"""
        try:
            settings_file = "app/data/ai_settings.json"
            
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ìƒì„±
            if not os.path.exists(settings_file):
                self._create_default_settings_file(settings_file)
            
            with open(settings_file, 'r', encoding='utf-8') as f:
                settings_data = json.load(f)
                return settings_data.get("provider", "openai")
        except Exception as e:
            logger.error(f"AI ì„¤ì • íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ê°’ì€ OpenAI
        return "openai"
    
    def _create_default_settings_file(self, settings_file: str):
        """ê¸°ë³¸ AI ì„¤ì • íŒŒì¼ ìƒì„±"""
        try:
            # data ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(os.path.dirname(settings_file), exist_ok=True)
            
            default_settings = {
                "provider": "openai",
                "last_updated": "2025-01-02T00:00:00Z",
                "settings": {
                    "openai": {
                        "model": "gpt-3.5-turbo",
                        "temperature": 0.7,
                        "max_tokens": 2000
                    },
                    "gemini": {
                        "model": "gemini-1.5-flash",
                        "temperature": 0.7,
                        "max_tokens": 2000
                    }
                }
            }
            
            with open(settings_file, 'w', encoding='utf-8') as f:
                json.dump(default_settings, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ê¸°ë³¸ AI ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ: {settings_file}")
            
        except Exception as e:
            logger.error(f"ê¸°ë³¸ AI ì„¤ì • íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
    
    async def generate_text(self, prompt: str, max_tokens: int = 2000) -> str:
        """
        í˜„ì¬ ì„¤ì •ëœ AI ì œê³µìë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±
        """
        current_provider = self._get_current_provider()
        
        # === Railway ë¡œê·¸: AI í˜¸ì¶œ ì‹œì‘ ===
        logger.info(f"ğŸ¤– [AI_START] AI í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘")
        logger.info(f"ğŸ”§ [AI_PROVIDER] í˜„ì¬ AI ì œê³µì: {current_provider}")
        logger.info(f"ğŸ“ [PROMPT_LENGTH] í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ê¸€ì")
        logger.info(f"ğŸ›ï¸ [MAX_TOKENS] ìµœëŒ€ í† í°: {max_tokens}")
        logger.info(f"ğŸ“ [PROMPT_PREVIEW] í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {prompt[:200]}...")
        
        try:
            if current_provider == "gemini":
                logger.info(f"ğŸŸ¢ [AI_GEMINI] Google Geminië¡œ í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘")
                result = await self._generate_with_gemini(prompt, max_tokens)
            else:
                logger.info(f"ğŸ”µ [AI_OPENAI] OpenAIë¡œ í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘")
                result = await self._generate_with_openai(prompt, max_tokens)
            
            # === Railway ë¡œê·¸: AI í˜¸ì¶œ ì„±ê³µ ===
            logger.info(f"âœ… [AI_SUCCESS] AI í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ")
            logger.info(f"ğŸ“Š [RESULT_LENGTH] ì‘ë‹µ ê¸¸ì´: {len(result)} ê¸€ì")
            logger.info(f"ğŸ“„ [RESULT_PREVIEW] ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {result[:200]}...")
            
            return result
            
        except Exception as e:
            # === Railway ë¡œê·¸: AI í˜¸ì¶œ ì‹¤íŒ¨ ===
            logger.error(f"âŒ [AI_ERROR] {current_provider} AI ìƒì„± ì‹¤íŒ¨")
            logger.error(f"ğŸš¨ [ERROR_TYPE] {type(e).__name__}")
            logger.error(f"ğŸ“ [ERROR_MESSAGE] {str(e)}")
            # ë‹¤ë¥¸ AIë¡œ ì¬ì‹œë„í•˜ì§€ ì•Šê³ , ì˜ˆì™¸ë¥¼ ê·¸ëŒ€ë¡œ ì˜¬ë ¤ fallback ì²˜ë¦¬
            raise
    
    async def _generate_with_openai(self, prompt: str, max_tokens: int) -> str:
        """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±"""
        if not self.openai_client:
            raise Exception("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì—¬í–‰ ì¼ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ìµœì ì˜ ì—¬í–‰ ì¼ì •ì„ ìƒì„±í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7
            )
            
            result = response.choices[0].message.content.strip()
            logger.info(f"OpenAI ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(result)} ê¸€ì)")
            return result
            
        except Exception as e:
            logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise Exception(f"OpenAI í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    async def _generate_with_gemini(self, prompt: str, max_tokens: int) -> str:
        """Google Geminië¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±"""
        if not self.gemini_model:
            raise Exception("Gemini ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            # Geminiìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            full_prompt = f"""ë‹¹ì‹ ì€ ì—¬í–‰ ì¼ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ìµœì ì˜ ì—¬í–‰ ì¼ì •ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ìš”ì²­:
{prompt}

ì‘ë‹µì€ ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ ì—¬í–‰ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."""

            response = self.gemini_model.generate_content(
                full_prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=max_tokens,
                    temperature=0.7,
                )
            )
            
            result = response.text.strip()
            logger.info(f"Gemini ì‘ë‹µ ìƒì„± ì™„ë£Œ ({len(result)} ê¸€ì)")
            return result
            
        except Exception as e:
            logger.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise Exception(f"Gemini í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def get_provider_info(self) -> Dict[str, Any]:
        """í˜„ì¬ AI ì œê³µì ì •ë³´ ë°˜í™˜"""
        current_provider = self._get_current_provider()
        
        provider_info = {
            "current_provider": current_provider,
            "available_providers": [],
            "provider_status": {}
        }
        
        # OpenAI ìƒíƒœ í™•ì¸
        if self.openai_client and settings.OPENAI_API_KEY:
            provider_info["available_providers"].append("openai")
            provider_info["provider_status"]["openai"] = "available"
        else:
            provider_info["provider_status"]["openai"] = "not_configured"
        
        # Gemini ìƒíƒœ í™•ì¸
        if self.gemini_model and settings.GEMINI_API_KEY:
            provider_info["available_providers"].append("gemini")
            provider_info["provider_status"]["gemini"] = "available"
        else:
            provider_info["provider_status"]["gemini"] = "not_configured"
        
        return provider_info

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
dynamic_ai_service = DynamicAIService() 